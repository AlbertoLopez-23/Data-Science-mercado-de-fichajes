import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, silhouette_samples
from sklearn.decomposition import PCA
import os
import warnings
import sys
from datetime import datetime
warnings.filterwarnings('ignore')

class TeeOutput:
    """Clase para duplicar la salida a consola y archivo"""
    def __init__(self, file_path):
        self.terminal = sys.stdout
        self.log = open(file_path, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        self.log.close()

def crear_carpeta_kmeans():
    """Crear carpeta k-means si no existe"""
    os.makedirs('k-means', exist_ok=True)
    print("üìÅ Carpeta 'k-means' creada/verificada")

def crear_boxplots_detallados(df_etiquetado, k_final, nombre_archivo, columna_objetivo):
    """
    Crear boxplots detallados para cada cluster mostrando la distribuci√≥n del valor de mercado
    """
    print(f"\nüìä CREANDO BOXPLOTS DETALLADOS para {nombre_archivo}")
    
    # Filtrar solo filas con cluster asignado (no -1)
    df_con_cluster = df_etiquetado[df_etiquetado['Cluster'] >= 0].copy()
    
    if len(df_con_cluster) == 0:
        print("   ‚ùå No hay datos con clusters asignados para crear boxplots")
        return
    
    # Crear figura con m√∫ltiples subplots
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'An√°lisis de Clusters - {nombre_archivo.replace(".csv", "").replace("08_db_", "").title()}', 
                 fontsize=16, fontweight='bold')
    
    # Subplot 1: Boxplot principal de valor de mercado por cluster
    ax1 = axes[0, 0]
    
    # Preparar datos para boxplot
    cluster_data = []
    cluster_labels = []
    cluster_colors = plt.cm.Set3(np.linspace(0, 1, k_final))
    
    for i in range(k_final):
        cluster_valores = df_con_cluster[df_con_cluster['Cluster'] == i][columna_objetivo]
        if len(cluster_valores) > 0:
            cluster_data.append(cluster_valores)
            cluster_labels.append(f'Cluster {i}\n(n={len(cluster_valores)})')
    
    # Crear boxplot
    bp1 = ax1.boxplot(cluster_data, labels=cluster_labels, patch_artist=True, 
                      showmeans=True, meanline=True)
    
    # Colorear boxplots
    for patch, color in zip(bp1['boxes'], cluster_colors[:len(cluster_data)]):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    ax1.set_title('Distribuci√≥n de Valor de Mercado por Cluster')
    ax1.set_ylabel('Valor de Mercado ($)')
    ax1.grid(True, alpha=0.3)
    ax1.tick_params(axis='x', rotation=45)
    
    # Formatear eje Y con notaci√≥n de millones
    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))
    
    # Subplot 2: Histograma de distribuci√≥n por cluster
    ax2 = axes[0, 1]
    
    for i in range(k_final):
        cluster_valores = df_con_cluster[df_con_cluster['Cluster'] == i][columna_objetivo]
        if len(cluster_valores) > 0:
            ax2.hist(cluster_valores, alpha=0.6, label=f'Cluster {i}', 
                    color=cluster_colors[i], bins=15, density=True)
    
    ax2.set_title('Distribuci√≥n de Densidad por Cluster')
    ax2.set_xlabel('Valor de Mercado ($)')
    ax2.set_ylabel('Densidad')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))
    
    # Subplot 3: Violin plot
    ax3 = axes[1, 0]
    
    # Preparar datos para violin plot
    violin_data = []
    violin_positions = []
    for i in range(k_final):
        cluster_valores = df_con_cluster[df_con_cluster['Cluster'] == i][columna_objetivo]
        if len(cluster_valores) > 0:
            violin_data.append(cluster_valores)
            violin_positions.append(i)
    
    if violin_data:
        parts = ax3.violinplot(violin_data, positions=violin_positions, showmeans=True, showmedians=True)
        
        # Colorear violin plots
        for pc, color in zip(parts['bodies'], cluster_colors[:len(violin_data)]):
            pc.set_facecolor(color)
            pc.set_alpha(0.7)
    
    ax3.set_title('Distribuci√≥n Detallada (Violin Plot)')
    ax3.set_xlabel('Cluster')
    ax3.set_ylabel('Valor de Mercado ($)')
    ax3.set_xticks(range(k_final))
    ax3.set_xticklabels([f'C{i}' for i in range(k_final)])
    ax3.grid(True, alpha=0.3)
    ax3.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))
    
    # Subplot 4: Estad√≠sticas por cluster
    ax4 = axes[1, 1]
    ax4.axis('off')  # Quitar ejes para mostrar tabla
    
    # Crear tabla de estad√≠sticas
    stats_data = []
    for i in range(k_final):
        cluster_valores = df_con_cluster[df_con_cluster['Cluster'] == i][columna_objetivo]
        if len(cluster_valores) > 0:
            stats_data.append([
                f'Cluster {i}',
                len(cluster_valores),
                f'${cluster_valores.mean():,.0f}',
                f'${cluster_valores.median():,.0f}',
                f'${cluster_valores.std():,.0f}',
                f'${cluster_valores.min():,.0f}',
                f'${cluster_valores.max():,.0f}'
            ])
    
    if stats_data:
        headers = ['Cluster', 'N', 'Media', 'Mediana', 'Std', 'Min', 'Max']
        table = ax4.table(cellText=stats_data, colLabels=headers, 
                         cellLoc='center', loc='center',
                         colColours=['lightblue']*len(headers))
        table.auto_set_font_size(False)
        table.set_fontsize(9)
        table.scale(1, 2)
        ax4.set_title('Estad√≠sticas por Cluster', pad=20)
    
    plt.tight_layout()
    
    # Guardar gr√°fico
    nombre_limpio = nombre_archivo.replace('.csv', '')
    plt.savefig(f'k-means/05_boxplots_detallados_{nombre_limpio}_k{k_final}.png', 
                dpi=300, bbox_inches='tight')
    print(f"üìä Boxplots detallados guardados: k-means/05_boxplots_detallados_{nombre_limpio}_k{k_final}.png")
    plt.close()
    
    # Crear gr√°fico adicional: Comparaci√≥n de clusters
    crear_grafico_comparacion_clusters(df_con_cluster, k_final, nombre_archivo, columna_objetivo)

def crear_grafico_comparacion_clusters(df_con_cluster, k_final, nombre_archivo, columna_objetivo):
    """
    Crear gr√°fico de comparaci√≥n entre clusters con m√∫ltiples m√©tricas
    """
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    fig.suptitle(f'Comparaci√≥n de Clusters - {nombre_archivo.replace(".csv", "").replace("08_db_", "").title()}', 
                 fontsize=14, fontweight='bold')
    
    cluster_colors = plt.cm.Set3(np.linspace(0, 1, k_final))
    
    # Gr√°fico 1: Tama√±o de clusters
    ax1 = axes[0]
    cluster_sizes = [len(df_con_cluster[df_con_cluster['Cluster'] == i]) for i in range(k_final)]
    bars1 = ax1.bar(range(k_final), cluster_sizes, color=cluster_colors, alpha=0.7)
    ax1.set_title('Tama√±o de Clusters')
    ax1.set_xlabel('Cluster')
    ax1.set_ylabel('N√∫mero de Jugadores')
    ax1.set_xticks(range(k_final))
    ax1.set_xticklabels([f'C{i}' for i in range(k_final)])
    
    # Agregar valores en las barras
    for bar, size in zip(bars1, cluster_sizes):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + max(cluster_sizes)*0.01,
                f'{size}', ha='center', va='bottom', fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # Gr√°fico 2: Valor promedio por cluster
    ax2 = axes[1]
    cluster_means = [df_con_cluster[df_con_cluster['Cluster'] == i][columna_objetivo].mean() 
                     for i in range(k_final)]
    bars2 = ax2.bar(range(k_final), cluster_means, color=cluster_colors, alpha=0.7)
    ax2.set_title('Valor Promedio por Cluster')
    ax2.set_xlabel('Cluster')
    ax2.set_ylabel('Valor Promedio ($)')
    ax2.set_xticks(range(k_final))
    ax2.set_xticklabels([f'C{i}' for i in range(k_final)])
    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))
    
    # Agregar valores en las barras
    for bar, mean_val in zip(bars2, cluster_means):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + max(cluster_means)*0.01,
                f'${mean_val/1e6:.1f}M', ha='center', va='bottom', fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # Gr√°fico 3: Rango de valores (min-max) por cluster
    ax3 = axes[2]
    cluster_mins = [df_con_cluster[df_con_cluster['Cluster'] == i][columna_objetivo].min() 
                    for i in range(k_final)]
    cluster_maxs = [df_con_cluster[df_con_cluster['Cluster'] == i][columna_objetivo].max() 
                    for i in range(k_final)]
    cluster_ranges = [max_val - min_val for min_val, max_val in zip(cluster_mins, cluster_maxs)]
    
    bars3 = ax3.bar(range(k_final), cluster_ranges, color=cluster_colors, alpha=0.7)
    ax3.set_title('Rango de Valores por Cluster')
    ax3.set_xlabel('Cluster')
    ax3.set_ylabel('Rango (Max - Min) ($)')
    ax3.set_xticks(range(k_final))
    ax3.set_xticklabels([f'C{i}' for i in range(k_final)])
    ax3.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))
    
    # Agregar valores en las barras
    for bar, range_val in zip(bars3, cluster_ranges):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + max(cluster_ranges)*0.01,
                f'${range_val/1e6:.1f}M', ha='center', va='bottom', fontweight='bold')
    ax3.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Guardar gr√°fico
    nombre_limpio = nombre_archivo.replace('.csv', '')
    plt.savefig(f'k-means/06_comparacion_clusters_{nombre_limpio}_k{k_final}.png', 
                dpi=300, bbox_inches='tight')
    print(f"üìä Comparaci√≥n de clusters guardada: k-means/06_comparacion_clusters_{nombre_limpio}_k{k_final}.png")
    plt.close()

def metodo_del_codo(X, nombre_archivo, max_k=10):
    """
    Implementa el m√©todo del codo para encontrar el n√∫mero √≥ptimo de clusters
    """
    print(f"\nüîç M√âTODO DEL CODO para {nombre_archivo}")
    print("-" * 50)
    
    # Calcular inercia para diferentes valores de K
    inercias = []
    K_range = range(1, max_k + 1)
    
    for k in K_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(X)
        inercias.append(kmeans.inertia_)
        print(f"   K={k}: Inercia = {kmeans.inertia_:.2f}")
    
    # Crear gr√°fico del codo
    plt.figure(figsize=(10, 6))
    plt.plot(K_range, inercias, 'bo-', linewidth=2, markersize=8)
    plt.xlabel('N√∫mero de Clusters (K)')
    plt.ylabel('Inercia (WCSS)')
    plt.title(f'M√©todo del Codo - {nombre_archivo}')
    plt.grid(True, alpha=0.3)
    
    # M√©todo mejorado para encontrar el codo usando el m√©todo de la distancia perpendicular
    if len(inercias) >= 3:
        # Normalizar los datos para el c√°lculo
        x_norm = np.array(K_range)
        y_norm = np.array(inercias)
        
        # Calcular distancias perpendiculares a la l√≠nea que conecta primer y √∫ltimo punto
        x1, y1 = x_norm[0], y_norm[0]  # Primer punto
        x2, y2 = x_norm[-1], y_norm[-1]  # √öltimo punto
        
        # Calcular distancias perpendiculares para cada punto
        distances = []
        for i in range(len(x_norm)):
            x_point, y_point = x_norm[i], y_norm[i]
            # F√≥rmula de distancia perpendicular de un punto a una l√≠nea
            numerator = abs((y2 - y1) * x_point - (x2 - x1) * y_point + x2 * y1 - y2 * x1)
            denominator = np.sqrt((y2 - y1)**2 + (x2 - x1)**2)
            distance = numerator / denominator
            distances.append(distance)
        
        # El codo est√° en el punto con mayor distancia perpendicular
        codo_idx = np.argmax(distances)
        k_optimo = K_range[codo_idx]
        
        # M√©todo alternativo: buscar el mayor cambio en la pendiente
        if len(inercias) >= 4:
            # Calcular diferencias y segunda derivada
            diff1 = np.diff(inercias)
            diff2 = np.diff(diff1)
            
            # Encontrar el punto donde la segunda derivada es m√°xima (cambio m√°s pronunciado)
            if len(diff2) > 0:
                codo_idx_alt = np.argmax(diff2) + 2  # +2 porque perdemos elementos en las diferencias
                k_optimo_alt = K_range[codo_idx_alt] if codo_idx_alt < len(K_range) else k_optimo
                
                # Si los m√©todos difieren mucho, usar el m√°s conservador (menor K)
                if abs(k_optimo - k_optimo_alt) > 1:
                    k_optimo = min(k_optimo, k_optimo_alt)
                    print(f"   M√©todos del codo difieren: usando K m√°s conservador = {k_optimo}")
        
        plt.axvline(x=k_optimo, color='red', linestyle='--', alpha=0.7, 
                   label=f'K √≥ptimo sugerido: {k_optimo}')
        plt.legend()
        
        print(f"   üéØ K √≥ptimo detectado por m√©todo del codo: {k_optimo}")
        print(f"   üìä Distancia perpendicular m√°xima en K={k_optimo}: {distances[codo_idx]:.2f}")
    else:
        k_optimo = 3  # Valor por defecto
        print(f"   ‚ö†Ô∏è Pocos puntos para an√°lisis, usando K por defecto: {k_optimo}")
    
    # Guardar gr√°fico
    nombre_limpio = nombre_archivo.replace('.csv', '')
    plt.savefig(f'k-means/01_metodo_codo_{nombre_limpio}.png', dpi=300, bbox_inches='tight')
    print(f"üìä Gr√°fico del codo guardado: k-means/01_metodo_codo_{nombre_limpio}.png")
    plt.close()
    
    return inercias, k_optimo

def analisis_silueta(X, nombre_archivo, k_range=range(2, 8)):
    """
    An√°lisis de silueta para diferentes valores de K
    """
    print(f"\nüìä AN√ÅLISIS DE SILUETA para {nombre_archivo}")
    print("-" * 50)
    
    scores_silueta = []
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(X)
        score = silhouette_score(X, cluster_labels)
        scores_silueta.append(score)
        print(f"   K={k}: Score de silueta = {score:.4f}")
    
    # Crear gr√°fico de silueta
    plt.figure(figsize=(10, 6))
    plt.plot(k_range, scores_silueta, 'go-', linewidth=2, markersize=8)
    plt.xlabel('N√∫mero de Clusters (K)')
    plt.ylabel('Score de Silueta')
    plt.title(f'An√°lisis de Silueta - {nombre_archivo}')
    plt.grid(True, alpha=0.3)
    
    # Marcar el mejor K
    mejor_k = k_range[np.argmax(scores_silueta)]
    mejor_score = max(scores_silueta)
    plt.axvline(x=mejor_k, color='red', linestyle='--', alpha=0.7,
               label=f'Mejor K: {mejor_k} (Score: {mejor_score:.4f})')
    plt.legend()
    
    # Guardar gr√°fico
    nombre_limpio = nombre_archivo.replace('.csv', '')
    plt.savefig(f'k-means/02_analisis_silueta_{nombre_limpio}.png', dpi=300, bbox_inches='tight')
    print(f"üìä Gr√°fico de silueta guardado: k-means/02_analisis_silueta_{nombre_limpio}.png")
    plt.close()
    
    return scores_silueta, mejor_k, mejor_score

def grafico_silueta_detallado(X, labels, k, nombre_archivo):
    """
    Crear gr√°fico detallado de silueta para un K espec√≠fico
    """
    # Calcular scores de silueta
    sample_silhouette_values = silhouette_samples(X, labels)
    silhouette_avg = silhouette_score(X, labels)
    
    # Crear figura
    fig, ax = plt.subplots(1, 1, figsize=(10, 8))
    
    y_lower = 10
    for i in range(k):
        # Valores de silueta para cluster i
        ith_cluster_silhouette_values = sample_silhouette_values[labels == i]
        ith_cluster_silhouette_values.sort()
        
        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i
        
        color = plt.cm.nipy_spectral(float(i) / k)
        ax.fill_betweenx(np.arange(y_lower, y_upper),
                        0, ith_cluster_silhouette_values,
                        facecolor=color, edgecolor=color, alpha=0.7)
        
        # Etiquetar clusters
        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
        y_lower = y_upper + 10
    
    ax.set_xlabel('Valores de Coeficiente de Silueta')
    ax.set_ylabel('√çndice de Cluster')
    ax.set_title(f'Gr√°fico de Silueta para K={k} - {nombre_archivo}\n'
                f'Score promedio: {silhouette_avg:.4f}')
    
    # L√≠nea vertical para el score promedio
    ax.axvline(x=silhouette_avg, color="red", linestyle="--",
              label=f'Score promedio: {silhouette_avg:.4f}')
    ax.legend()
    
    # Guardar gr√°fico
    nombre_limpio = nombre_archivo.replace('.csv', '')
    plt.savefig(f'k-means/03_silueta_detallada_{nombre_limpio}_k{k}.png', dpi=300, bbox_inches='tight')
    print(f"üìä Gr√°fico detallado de silueta guardado: k-means/03_silueta_detallada_{nombre_limpio}_k{k}.png")
    plt.close()
    
    return silhouette_avg

def visualizar_clusters_2d(X_original, X_scaled, labels, centroids, k, nombre_archivo, feature_names, columna_objetivo):
    """
    Visualizar clusters en 2D usando PCA
    """
    # Aplicar PCA para reducir a 2D
    pca = PCA(n_components=2, random_state=42)
    X_pca = pca.fit_transform(X_scaled)
    centroids_pca = pca.transform(centroids)
    
    # Crear figura con subplots
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # Gr√°fico 1: Clusters en espacio PCA
    colors = plt.cm.nipy_spectral(np.linspace(0, 1, k))
    for i in range(k):
        mask = labels == i
        ax1.scatter(X_pca[mask, 0], X_pca[mask, 1], 
                   c=[colors[i]], label=f'Cluster {i}', alpha=0.7, s=50)
    
    # Centroids en PCA
    ax1.scatter(centroids_pca[:, 0], centroids_pca[:, 1], 
               c='red', marker='x', s=200, linewidths=3, label='Centroids')
    ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} varianza)')
    ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} varianza)')
    ax1.set_title(f'Clusters en Espacio PCA (K={k})')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Encontrar la columna del valor de mercado en X_original
    if isinstance(X_original, pd.DataFrame):
        if columna_objetivo in X_original.columns:
            valor_mercado = X_original[columna_objetivo].values
        else:
            # Si no est√°, usar la primera columna num√©rica
            valor_mercado = X_original.iloc[:, 0].values
    else:
        # Si es numpy array, usar la primera columna
        valor_mercado = X_original[:, 0]
    
    # Gr√°fico 2: Distribuci√≥n del valor de mercado por cluster
    for i in range(k):
        mask = labels == i
        ax2.hist(valor_mercado[mask], alpha=0.7, label=f'Cluster {i}', 
                bins=20, color=colors[i])
    ax2.set_xlabel('Valor de Mercado')
    ax2.set_ylabel('Frecuencia')
    ax2.set_title('Distribuci√≥n de Valor de Mercado por Cluster')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Gr√°fico 3: Boxplot del valor de mercado por cluster
    data_boxplot = [valor_mercado[labels == i] for i in range(k)]
    bp = ax3.boxplot(data_boxplot, labels=[f'C{i}' for i in range(k)], patch_artist=True)
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    ax3.set_xlabel('Cluster')
    ax3.set_ylabel('Valor de Mercado')
    ax3.set_title('Distribuci√≥n de Valor de Mercado por Cluster')
    ax3.grid(True, alpha=0.3)
    
    # Gr√°fico 4: Tama√±o de clusters
    cluster_sizes = [np.sum(labels == i) for i in range(k)]
    ax4.bar(range(k), cluster_sizes, color=colors, alpha=0.7)
    ax4.set_xlabel('Cluster')
    ax4.set_ylabel('N√∫mero de Jugadores')
    ax4.set_title('Tama√±o de Clusters')
    ax4.set_xticks(range(k))
    ax4.set_xticklabels([f'C{i}' for i in range(k)])
    for i, size in enumerate(cluster_sizes):
        ax4.text(i, size + max(cluster_sizes)*0.01, str(size), 
                ha='center', va='bottom')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Guardar gr√°fico
    nombre_limpio = nombre_archivo.replace('.csv', '')
    plt.savefig(f'k-means/04_visualizacion_clusters_{nombre_limpio}_k{k}.png', dpi=300, bbox_inches='tight')
    print(f"üìä Visualizaci√≥n de clusters guardada: k-means/04_visualizacion_clusters_{nombre_limpio}_k{k}.png")
    plt.close()
    
    return pca.explained_variance_ratio_

def crear_grafico_dispersion_clusters(df_etiquetado, k_final, nombre_archivo, columna_objetivo, columna_overall):
    """
    Crear gr√°fico de dispersi√≥n coloreado por clusters usando valor de mercado y overall
    """
    print(f"\nüé® CREANDO GR√ÅFICO DE DISPERSI√ìN POR CLUSTERS para {nombre_archivo}")
    
    # Filtrar solo filas con cluster asignado (no -1)
    df_con_cluster = df_etiquetado[df_etiquetado['Cluster'] >= 0].copy()
    
    if len(df_con_cluster) == 0:
        print("   ‚ùå No hay datos con clusters asignados para crear dispersi√≥n")
        return
    
    # Crear figura principal
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'An√°lisis de Dispersi√≥n por Clusters - {nombre_archivo.replace(".csv", "").replace("08_db_", "").title()}', 
                 fontsize=16, fontweight='bold')
    
    # Definir colores para los clusters
    cluster_colors = plt.cm.Set3(np.linspace(0, 1, k_final))
    
    # Gr√°fico 1: Dispersi√≥n principal (Overall vs Valor de Mercado)
    ax1 = axes[0, 0]
    
    for i in range(k_final):
        cluster_data = df_con_cluster[df_con_cluster['Cluster'] == i]
        if len(cluster_data) > 0:
            ax1.scatter(cluster_data[columna_overall], cluster_data[columna_objetivo], 
                       c=[cluster_colors[i]], label=f'Cluster {i} (n={len(cluster_data)})', 
                       alpha=0.7, s=60, edgecolors='black', linewidth=0.5)
    
    ax1.set_xlabel('Overall Rating')
    ax1.set_ylabel('Valor de Mercado ($)')
    ax1.set_title('Dispersi√≥n: Overall Rating vs Valor de Mercado')
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax1.grid(True, alpha=0.3)
    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))
    
    # Gr√°fico 2: Dispersi√≥n con densidad
    ax2 = axes[0, 1]
    
    # Crear un scatter plot con diferentes tama√±os basados en densidad local
    for i in range(k_final):
        cluster_data = df_con_cluster[df_con_cluster['Cluster'] == i]
        if len(cluster_data) > 0:
            # Calcular tama√±os basados en la densidad del cluster
            sizes = np.full(len(cluster_data), 50 + 100/max(1, len(cluster_data)/10))
            ax2.scatter(cluster_data[columna_overall], cluster_data[columna_objetivo], 
                       c=[cluster_colors[i]], label=f'Cluster {i}', 
                       alpha=0.6, s=sizes, edgecolors='white', linewidth=1)
    
    ax2.set_xlabel('Overall Rating')
    ax2.set_ylabel('Valor de Mercado ($)')
    ax2.set_title('Dispersi√≥n con Densidad por Cluster')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))
    
    # Gr√°fico 3: Distribuci√≥n marginal de Overall Rating
    ax3 = axes[1, 0]
    
    for i in range(k_final):
        cluster_data = df_con_cluster[df_con_cluster['Cluster'] == i]
        if len(cluster_data) > 0:
            ax3.hist(cluster_data[columna_overall], alpha=0.6, label=f'Cluster {i}', 
                    color=cluster_colors[i], bins=15, density=True)
    
    ax3.set_xlabel('Overall Rating')
    ax3.set_ylabel('Densidad')
    ax3.set_title('Distribuci√≥n de Overall Rating por Cluster')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Gr√°fico 4: Estad√≠sticas comparativas
    ax4 = axes[1, 1]
    
    # Crear gr√°fico de barras comparativo
    cluster_stats = []
    cluster_labels = []
    overall_means = []
    value_means = []
    
    for i in range(k_final):
        cluster_data = df_con_cluster[df_con_cluster['Cluster'] == i]
        if len(cluster_data) > 0:
            cluster_labels.append(f'C{i}')
            overall_means.append(cluster_data[columna_overall].mean())
            value_means.append(cluster_data[columna_objetivo].mean() / 1e6)  # En millones
    
    x = np.arange(len(cluster_labels))
    width = 0.35
    
    # Normalizar overall ratings para comparaci√≥n visual
    overall_normalized = np.array(overall_means) / max(overall_means) * max(value_means)
    
    bars1 = ax4.bar(x - width/2, value_means, width, label='Valor Medio (M$)', 
                    color=[cluster_colors[i] for i in range(len(cluster_labels))], alpha=0.7)
    bars2 = ax4.bar(x + width/2, overall_normalized, width, label='Overall Medio (Norm.)', 
                    color=[cluster_colors[i] for i in range(len(cluster_labels))], alpha=0.4)
    
    ax4.set_xlabel('Cluster')
    ax4.set_ylabel('Valor')
    ax4.set_title('Comparaci√≥n de Medias por Cluster')
    ax4.set_xticks(x)
    ax4.set_xticklabels(cluster_labels)
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # A√±adir valores en las barras
    for bar, val in zip(bars1, value_means):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + max(value_means)*0.01,
                f'{val:.1f}M', ha='center', va='bottom', fontsize=9)
    
    for bar, val in zip(bars2, overall_means):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + max(overall_normalized)*0.01,
                f'{val:.0f}', ha='center', va='bottom', fontsize=9)
    
    plt.tight_layout()
    
    # Guardar gr√°fico
    nombre_limpio = nombre_archivo.replace('.csv', '')
    plt.savefig(f'k-means/07_dispersion_clusters_{nombre_limpio}_k{k_final}.png', 
                dpi=300, bbox_inches='tight')
    print(f"üé® Gr√°fico de dispersi√≥n guardado: k-means/07_dispersion_clusters_{nombre_limpio}_k{k_final}.png")
    plt.close()
    
    # Crear gr√°fico adicional de dispersi√≥n grande
    crear_grafico_dispersion_grande(df_con_cluster, k_final, nombre_archivo, columna_objetivo, columna_overall, cluster_colors)

def crear_grafico_dispersion_grande(df_con_cluster, k_final, nombre_archivo, columna_objetivo, columna_overall, cluster_colors):
    """
    Crear un gr√°fico de dispersi√≥n grande y detallado
    """
    fig, ax = plt.subplots(1, 1, figsize=(14, 10))
    
    # Crear scatter plot principal
    for i in range(k_final):
        cluster_data = df_con_cluster[df_con_cluster['Cluster'] == i]
        if len(cluster_data) > 0:
            ax.scatter(cluster_data[columna_overall], cluster_data[columna_objetivo], 
                      c=[cluster_colors[i]], label=f'Cluster {i} (n={len(cluster_data)})', 
                      alpha=0.7, s=80, edgecolors='black', linewidth=0.5)
    
    # Calcular y dibujar centroides
    centroids_overall = []
    centroids_value = []
    
    for i in range(k_final):
        cluster_data = df_con_cluster[df_con_cluster['Cluster'] == i]
        if len(cluster_data) > 0:
            centroid_overall = cluster_data[columna_overall].mean()
            centroid_value = cluster_data[columna_objetivo].mean()
            centroids_overall.append(centroid_overall)
            centroids_value.append(centroid_value)
            
            # Dibujar centroide
            ax.scatter(centroid_overall, centroid_value, 
                      c='red', marker='X', s=200, linewidths=2, 
                      edgecolors='black', alpha=0.9)
            
            # Etiqueta del centroide
            ax.annotate(f'C{i}', (centroid_overall, centroid_value), 
                       xytext=(5, 5), textcoords='offset points', 
                       fontsize=12, fontweight='bold', color='red')
    
    ax.set_xlabel('Overall Rating', fontsize=14)
    ax.set_ylabel('Valor de Mercado ($)', fontsize=14)
    ax.set_title(f'Clustering: Overall Rating vs Valor de Mercado\n{nombre_archivo.replace(".csv", "").replace("08_db_", "").title()}', 
                fontsize=16, fontweight='bold')
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, alpha=0.3)
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))
    
    # A√±adir estad√≠sticas en el gr√°fico
    textstr = f'Clusters: {k_final}\n'
    textstr += f'Total jugadores: {len(df_con_cluster)}\n'
    textstr += f'Overall range: {df_con_cluster[columna_overall].min():.0f}-{df_con_cluster[columna_overall].max():.0f}\n'
    textstr += f'Valor range: ${df_con_cluster[columna_objetivo].min()/1e6:.1f}M-${df_con_cluster[columna_objetivo].max()/1e6:.1f}M'
    
    props = dict(boxstyle='round', facecolor='lightblue', alpha=0.8)
    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10,
            verticalalignment='top', bbox=props)
    
    plt.tight_layout()
    
    # Guardar gr√°fico
    nombre_limpio = nombre_archivo.replace('.csv', '')
    plt.savefig(f'k-means/08_dispersion_grande_{nombre_limpio}_k{k_final}.png', 
                dpi=300, bbox_inches='tight')
    print(f"üé® Gr√°fico de dispersi√≥n grande guardado: k-means/08_dispersion_grande_{nombre_limpio}_k{k_final}.png")
    plt.close()

def evaluar_calidad_clusters(X_scaled, labels, k_final, nombre_archivo, kmeans_model):
    """
    Evaluar la calidad de los clusters usando m√∫ltiples m√©tricas
    """
    print(f"\nüìä EVALUACI√ìN DE CALIDAD DE CLUSTERS:")
    print("-" * 50)
    
    # 1. Score de Silueta
    silueta_score = silhouette_score(X_scaled, labels)
    print(f"   üéØ Score de Silueta Global: {silueta_score:.4f}")
    
    # Interpretaci√≥n del score de silueta
    if silueta_score >= 0.7:
        calidad_silueta = "EXCELENTE"
        emoji_silueta = "üü¢"
    elif silueta_score >= 0.5:
        calidad_silueta = "BUENA"
        emoji_silueta = "üü°"
    elif silueta_score >= 0.25:
        calidad_silueta = "REGULAR"
        emoji_silueta = "üü†"
    else:
        calidad_silueta = "POBRE"
        emoji_silueta = "üî¥"
    
    print(f"   {emoji_silueta} Calidad seg√∫n Silueta: {calidad_silueta}")
    
    # 2. Inercia y m√©tricas relacionadas
    inercia_total = kmeans_model.inertia_
    print(f"   üìâ Inercia Total (WCSS): {inercia_total:.2f}")
    
    # Calcular inercia promedio por cluster
    inercia_promedio = inercia_total / k_final
    print(f"   üìä Inercia Promedio por Cluster: {inercia_promedio:.2f}")
    
    # 3. An√°lisis por cluster individual
    print(f"\n   üìã AN√ÅLISIS POR CLUSTER INDIVIDUAL:")
    
    # Calcular scores de silueta por muestra
    sample_silhouette_values = silhouette_samples(X_scaled, labels)
    
    cluster_qualities = []
    for i in range(k_final):
        # Filtrar datos de este cluster
        cluster_mask = labels == i
        cluster_size = np.sum(cluster_mask)
        
        if cluster_size > 0:
            # Score de silueta para este cluster
            cluster_silhouette_values = sample_silhouette_values[cluster_mask]
            cluster_silhouette_mean = cluster_silhouette_values.mean()
            cluster_silhouette_std = cluster_silhouette_values.std()
            
            # Calcular inercia intra-cluster (distancia al centroide)
            cluster_data = X_scaled[cluster_mask]
            centroid = kmeans_model.cluster_centers_[i]
            intra_cluster_distances = np.sum((cluster_data - centroid) ** 2, axis=1)
            inercia_cluster = np.sum(intra_cluster_distances)
            inercia_promedio_cluster = inercia_cluster / cluster_size
            
            print(f"     Cluster {i}:")
            print(f"       üë• Tama√±o: {cluster_size}")
            print(f"       üéØ Silueta promedio: {cluster_silhouette_mean:.4f} ¬± {cluster_silhouette_std:.4f}")
            print(f"       üìâ Inercia intra-cluster: {inercia_cluster:.2f}")
            print(f"       üìä Inercia promedio por punto: {inercia_promedio_cluster:.4f}")
            
            # Evaluar calidad individual del cluster
            if cluster_silhouette_mean >= 0.5:
                calidad_individual = "BUENA"
                emoji_individual = "üü¢"
            elif cluster_silhouette_mean >= 0.25:
                calidad_individual = "REGULAR"
                emoji_individual = "üü°"
            else:
                calidad_individual = "POBRE"
                emoji_individual = "üî¥"
            
            print(f"       {emoji_individual} Calidad: {calidad_individual}")
            
            cluster_qualities.append({
                'cluster': i,
                'size': cluster_size,
                'silhouette_mean': cluster_silhouette_mean,
                'silhouette_std': cluster_silhouette_std,
                'inertia': inercia_cluster,
                'inertia_per_point': inercia_promedio_cluster,
                'quality': calidad_individual
            })
    
    # 4. M√©tricas de cohesi√≥n y separaci√≥n
    print(f"\n   üìà M√âTRICAS DE COHESI√ìN Y SEPARACI√ìN:")
    
    # Distancia entre centroides (separaci√≥n)
    centroids = kmeans_model.cluster_centers_
    min_centroid_distance = float('inf')
    max_centroid_distance = 0
    
    for i in range(k_final):
        for j in range(i+1, k_final):
            distance = np.linalg.norm(centroids[i] - centroids[j])
            min_centroid_distance = min(min_centroid_distance, distance)
            max_centroid_distance = max(max_centroid_distance, distance)
    
    print(f"     üîÑ Distancia m√≠nima entre centroides: {min_centroid_distance:.4f}")
    print(f"     üîÑ Distancia m√°xima entre centroides: {max_centroid_distance:.4f}")
    print(f"     üìè Ratio separaci√≥n (max/min): {max_centroid_distance/min_centroid_distance:.2f}")
    
    # 5. Resumen de calidad
    print(f"\n   üèÜ RESUMEN DE CALIDAD:")
    clusters_buenos = sum(1 for c in cluster_qualities if c['quality'] == 'BUENA')
    clusters_regulares = sum(1 for c in cluster_qualities if c['quality'] == 'REGULAR')
    clusters_pobres = sum(1 for c in cluster_qualities if c['quality'] == 'POBRE')
    
    print(f"     üü¢ Clusters de calidad BUENA: {clusters_buenos}/{k_final}")
    print(f"     üü° Clusters de calidad REGULAR: {clusters_regulares}/{k_final}")
    print(f"     üî¥ Clusters de calidad POBRE: {clusters_pobres}/{k_final}")
    
    # Calidad general del clustering
    if clusters_pobres == 0 and clusters_buenos >= k_final // 2:
        calidad_general = "EXCELENTE"
        emoji_general = "üåü"
    elif clusters_pobres <= k_final // 4:
        calidad_general = "BUENA"
        emoji_general = "‚úÖ"
    elif clusters_pobres <= k_final // 2:
        calidad_general = "REGULAR"
        emoji_general = "‚ö†Ô∏è"
    else:
        calidad_general = "POBRE"
        emoji_general = "‚ùå"
    
    print(f"     {emoji_general} CALIDAD GENERAL DEL CLUSTERING: {calidad_general}")
    
    return {
        'silhouette_score': silueta_score,
        'inertia_total': inercia_total,
        'inertia_promedio': inercia_promedio,
        'min_centroid_distance': min_centroid_distance,
        'max_centroid_distance': max_centroid_distance,
        'separation_ratio': max_centroid_distance/min_centroid_distance,
        'clusters_buenos': clusters_buenos,
        'clusters_regulares': clusters_regulares,
        'clusters_pobres': clusters_pobres,
        'calidad_general': calidad_general,
        'cluster_details': cluster_qualities
    }

def procesar_archivo_csv(archivo_path, carpeta_origen="DB_separadas"):
    """
    Procesar un archivo CSV individual para clustering usando solo Overall Rating y Valor de Mercado
    """
    nombre_archivo = os.path.basename(archivo_path)
    print(f"\n{'='*60}")
    print(f"üéØ PROCESANDO: {nombre_archivo}")
    print(f"{'='*60}")
    
    try:
        # Cargar datos
        df = pd.read_csv(archivo_path)
        print(f"üìä Dimensiones del dataset: {df.shape}")
        
        # Definir las dos columnas espec√≠ficas para clustering
        columna_objetivo = 'Valor de mercado actual (num√©rico)'
        columna_overall = 'overallrating'
        
        # Verificar que existen ambas columnas
        if columna_objetivo not in df.columns:
            print(f"‚ùå ERROR: Columna '{columna_objetivo}' no encontrada")
            return None
            
        if columna_overall not in df.columns:
            print(f"‚ùå ERROR: Columna '{columna_overall}' no encontrada")
            return None
        
        # Preparar datos para clustering
        print(f"\nüîß PREPARANDO DATOS PARA CLUSTERING:")
        print(f"   üìä Variables seleccionadas para clustering:")
        print(f"   - {columna_objetivo} (Variable objetivo)")
        print(f"   - {columna_overall} (Rating FIFA)")
        
        # Crear dataset para clustering con solo estas dos variables
        X_original = df[[columna_objetivo, columna_overall]].copy()
        
        # Eliminar filas con valores faltantes
        filas_antes = len(X_original)
        X_original = X_original.dropna()
        filas_despues = len(X_original)
        
        print(f"   Filas antes de limpiar: {filas_antes}")
        print(f"   Filas despu√©s de limpiar: {filas_despues}")
        print(f"   Filas eliminadas: {filas_antes - filas_despues}")
        
        if len(X_original) < 10:
            print(f"‚ùå ERROR: Muy pocas muestras v√°lidas ({len(X_original)})")
            return None
        
        # Estad√≠sticas de las variables
        print(f"\nüìà ESTAD√çSTICAS DE LAS VARIABLES:")
        print(f"   {columna_objetivo}:")
        print(f"     M√≠nimo: ${X_original[columna_objetivo].min():,.0f}")
        print(f"     M√°ximo: ${X_original[columna_objetivo].max():,.0f}")
        print(f"     Promedio: ${X_original[columna_objetivo].mean():,.0f}")
        print(f"     Mediana: ${X_original[columna_objetivo].median():,.0f}")
        
        print(f"   {columna_overall}:")
        print(f"     M√≠nimo: {X_original[columna_overall].min():.0f}")
        print(f"     M√°ximo: {X_original[columna_overall].max():.0f}")
        print(f"     Promedio: {X_original[columna_overall].mean():.1f}")
        print(f"     Mediana: {X_original[columna_overall].median():.0f}")
        
        # Estandarizar datos
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_original)
        
        print(f"   Datos estandarizados: {X_scaled.shape}")
        
        # Determinar rango de K para an√°lisis
        max_k = min(10, len(X_original) // 5)  # M√°ximo 10 o 1/5 del dataset
        k_range = range(2, max_k + 1)
        
        print(f"   Rango de K para an√°lisis: {list(k_range)}")
        
        # 1. M√©todo del codo
        inercias, k_codo = metodo_del_codo(X_scaled, nombre_archivo, max_k)
        
        # 2. An√°lisis de silueta
        scores_silueta, k_silueta, mejor_score_silueta = analisis_silueta(X_scaled, nombre_archivo, k_range)
        
        # 3. Decidir K final - PRIORIDAD AL M√âTODO DEL CODO
        k_final = k_codo  # Siempre usar el m√©todo del codo como primera opci√≥n
        
        # Solo ajustar si el codo sugiere algo extremo
        if k_codo < 2:
            k_final = 2  # M√≠nimo 2 clusters
        elif k_codo > max_k:
            k_final = max_k  # No exceder el m√°ximo
        
        print(f"\nüéØ DECISI√ìN DE K:")
        print(f"   K sugerido por m√©todo del codo: {k_codo} ‚≠ê (PRIORITARIO)")
        print(f"   K sugerido por an√°lisis de silueta: {k_silueta} (score: {mejor_score_silueta:.4f})")
        print(f"   K FINAL seleccionado: {k_final}")
        print(f"   L√≥gica aplicada: Prioridad absoluta al m√©todo del codo")
        
        # Mostrar comparaci√≥n informativa
        if k_codo == k_silueta:
            print(f"   ‚úÖ Ambos m√©todos coinciden en K={k_final}")
        elif abs(k_codo - k_silueta) <= 1:
            print(f"   ‚úÖ M√©todos muy cercanos (diferencia ‚â§ 1)")
        else:
            print(f"   ‚ö†Ô∏è M√©todos difieren significativamente (diferencia = {abs(k_codo - k_silueta)})")
            print(f"       Manteniendo K del codo = {k_final} por prioridad establecida")
        
        # 4. Aplicar K-means con K final
        print(f"\nüîÑ APLICANDO K-MEANS CON K={k_final}:")
        
        kmeans_final = KMeans(n_clusters=k_final, random_state=42, n_init=10)
        labels_final = kmeans_final.fit_predict(X_scaled)
        centroids_final = kmeans_final.cluster_centers_
        
        # ASEGURAR QUE LOS CLUSTERS SEAN SOLO POSITIVOS (0, 1, 2, ...)
        # Los clusters ya son positivos por defecto en sklearn, pero verificamos
        assert np.all(labels_final >= 0), "Error: Se encontraron clusters negativos"
        
        # M√©tricas b√°sicas
        inercia_final = kmeans_final.inertia_
        silueta_final = silhouette_score(X_scaled, labels_final)
        
        print(f"   ‚úÖ Clustering completado exitosamente")
        print(f"   üìä Clusters generados: {sorted(np.unique(labels_final))}")
        print(f"   üìâ Inercia total: {inercia_final:.2f}")
        print(f"   üéØ Score de silueta: {silueta_final:.4f}")
        
        # 5. EVALUACI√ìN DETALLADA DE CALIDAD
        calidad_info = evaluar_calidad_clusters(X_scaled, labels_final, k_final, nombre_archivo, kmeans_final)
        
        # 6. An√°lisis de clusters con informaci√≥n de calidad
        print(f"\nüìä AN√ÅLISIS DE CLUSTERS CON DATOS ORIGINALES:")
        for i in range(k_final):
            mask = labels_final == i
            cluster_size = np.sum(mask)
            
            # Obtener valores para este cluster
            cluster_valores = X_original.iloc[mask][columna_objetivo]
            cluster_overall = X_original.iloc[mask][columna_overall]
            
            # Obtener informaci√≥n de calidad de este cluster
            cluster_quality_info = next(
                (c for c in calidad_info['cluster_details'] if c['cluster'] == i), 
                None
            )
            
            print(f"   Cluster {i}: {cluster_size} jugadores")
            print(f"     üí∞ Valor promedio: ${cluster_valores.mean():,.0f}")
            print(f"     üéÆ Overall promedio: {cluster_overall.mean():.1f}")
            print(f"     üí∞ Valor mediana: ${cluster_valores.median():,.0f}")
            print(f"     üéÆ Overall mediana: {cluster_overall.median():.0f}")
            
            if cluster_quality_info:
                emoji_calidad = "üü¢" if cluster_quality_info['quality'] == 'BUENA' else "üü°" if cluster_quality_info['quality'] == 'REGULAR' else "üî¥"
                print(f"     {emoji_calidad} Calidad del cluster: {cluster_quality_info['quality']}")
                print(f"     üéØ Score silueta cluster: {cluster_quality_info['silhouette_mean']:.4f}")
                print(f"     üìâ Inercia intra-cluster: {cluster_quality_info['inertia']:.2f}")
        
        # 7. Crear visualizaciones
        print(f"\nüìä CREANDO VISUALIZACIONES:")
        
        # Gr√°fico detallado de silueta
        grafico_silueta_detallado(X_scaled, labels_final, k_final, nombre_archivo)
        
        # Visualizaci√≥n de clusters en 2D (ya no necesitamos PCA porque usamos solo 2 variables)
        print("   Saltando PCA - usando variables originales para visualizaci√≥n")
        
        # 8. Guardar dataset etiquetado
        print(f"\nüíæ GUARDANDO DATASET ETIQUETADO:")
        
        # Crear DataFrame con etiquetas
        df_etiquetado = df.copy()
        
        # Crear columna de cluster (inicializar con -1 para filas eliminadas)
        df_etiquetado['Cluster'] = -1
        
        # Asignar etiquetas solo a las filas v√°lidas (SOLO POSITIVOS: 0, 1, 2, ...)
        indices_validos = X_original.index
        df_etiquetado.loc[indices_validos, 'Cluster'] = labels_final
        
        # Verificar que no hay clusters negativos en el dataset final
        clusters_asignados = df_etiquetado[df_etiquetado['Cluster'] >= 0]['Cluster'].unique()
        print(f"   Clusters asignados en dataset: {sorted(clusters_asignados)}")
        
        # Crear nombre de archivo de salida
        nombre_salida = nombre_archivo.replace('07_db_', '09_db_').replace('08_db_', '09_db_')
        if not nombre_salida.startswith('09_db_'):
            nombre_salida = '09_db_' + nombre_salida
        
        ruta_salida = os.path.join(carpeta_origen, nombre_salida)
        df_etiquetado.to_csv(ruta_salida, index=False)
        
        print(f"   ‚úÖ Dataset etiquetado guardado: {ruta_salida}")
        print(f"   üìä Dimensiones: {df_etiquetado.shape}")
        print(f"   üè∑Ô∏è Filas con cluster asignado: {(df_etiquetado['Cluster'] >= 0).sum()}")
        print(f"   ‚ùå Filas sin cluster (datos faltantes): {(df_etiquetado['Cluster'] == -1).sum()}")
        
        # 9. CREAR BOXPLOTS DETALLADOS
        crear_boxplots_detallados(df_etiquetado, k_final, nombre_archivo, columna_objetivo)
        
        # 10. CREAR GR√ÅFICOS DE DISPERSI√ìN POR CLUSTERS
        crear_grafico_dispersion_clusters(df_etiquetado, k_final, nombre_archivo, columna_objetivo, columna_overall)
        
        # 11. Guardar resumen de an√°lisis
        resumen = {
            'archivo': nombre_archivo,
            'filas_totales': len(df),
            'filas_validas': len(X_original),
            'variables_clustering': f'{columna_objetivo} + {columna_overall}',
            'k_codo': k_codo,
            'k_silueta': k_silueta,
            'k_final': k_final,
            'inertia_total': inercia_final,
            'silueta_final': silueta_final
        }
        
        # Agregar estad√≠sticas por cluster
        for i in range(k_final):
            mask = labels_final == i
            cluster_valores = X_original.iloc[mask][columna_objetivo]
            cluster_overall = X_original.iloc[mask][columna_overall]
            
            resumen[f'cluster_{i}_size'] = len(cluster_valores)
            resumen[f'cluster_{i}_valor_promedio'] = cluster_valores.mean()
            resumen[f'cluster_{i}_valor_mediana'] = cluster_valores.median()
            resumen[f'cluster_{i}_overall_promedio'] = cluster_overall.mean()
            resumen[f'cluster_{i}_overall_mediana'] = cluster_overall.median()
        
        # La informaci√≥n de calidad ya est√° incluida en calidad_info
        resumen.update(calidad_info)
        
        return resumen
        
    except Exception as e:
        print(f"‚ùå ERROR procesando {nombre_archivo}: {str(e)}")
        import traceback
        print(f"   Detalles del error: {traceback.format_exc()}")
        return None

def clustering_todos_archivos(carpeta="DB_separadas"):
    """
    Aplicar clustering a todos los archivos CSV en la carpeta especificada
    """
    print("üöÄ INICIANDO CLUSTERING K-MEANS PARA TODOS LOS ARCHIVOS")
    print("="*60)
    print("üéØ CONFIGURACI√ìN DEL AN√ÅLISIS:")
    print("   üìä Variables para clustering: Valor de mercado + Overall rating") 
    print("   üîç M√©todo de selecci√≥n K: PRIORIDAD AL M√âTODO DEL CODO")
    print("   üìà M√©todo de silueta: Solo como informaci√≥n complementaria")
    print("="*60)
    
    # Crear carpeta para gr√°ficos
    crear_carpeta_kmeans()
    
    # Obtener lista de archivos CSV
    archivos_csv = [f for f in os.listdir(carpeta) if f.endswith('.csv')]
    
    if not archivos_csv:
        print(f"‚ùå No se encontraron archivos CSV en la carpeta {carpeta}")
        return
    
    print(f"üìÅ Carpeta de origen: {carpeta}")
    print(f"üìä Archivos encontrados: {len(archivos_csv)}")
    print(f"üìÅ Gr√°ficos se guardar√°n en: k-means/")
    print(f"üìÅ Datasets etiquetados se guardar√°n en: {carpeta}/")
    
    # Procesar cada archivo
    resultados = []
    archivos_procesados = 0
    archivos_con_error = 0
    
    for archivo in archivos_csv:
        ruta_archivo = os.path.join(carpeta, archivo)
        resultado = procesar_archivo_csv(ruta_archivo, carpeta)
        
        if resultado is not None:
            resultados.append(resultado)
            archivos_procesados += 1
        else:
            archivos_con_error += 1
    
    # Resumen final
    print(f"\n{'='*60}")
    print("üìã RESUMEN FINAL DEL CLUSTERING")
    print(f"{'='*60}")
    
    print(f"üìä Archivos procesados exitosamente: {archivos_procesados}")
    print(f"‚ùå Archivos con errores: {archivos_con_error}")
    print(f"üìÅ Total de archivos: {len(archivos_csv)}")
    
    if resultados:
        # Crear DataFrame con resumen
        df_resumen = pd.DataFrame(resultados)
        
        # Guardar resumen
        df_resumen.to_csv('k-means/00_resumen_clustering.csv', index=False)
        print(f"üíæ Resumen guardado: k-means/00_resumen_clustering.csv")
        
        # Estad√≠sticas generales
        print(f"\nüìà ESTAD√çSTICAS GENERALES:")
        print(f"   K promedio seleccionado (m√©todo del codo): {df_resumen['k_final'].mean():.1f}")
        print(f"   K del codo promedio original: {df_resumen['k_codo'].mean():.1f}")
        print(f"   K de silueta promedio (referencia): {df_resumen['k_silueta'].mean():.1f}")
        print(f"   Score de silueta promedio: {df_resumen['silueta_final'].mean():.4f}")
        print(f"   Inercia promedio: {df_resumen['inertia_total'].mean():.2f}")
        print(f"   Rango de K utilizados: {df_resumen['k_final'].min()} - {df_resumen['k_final'].max()}")
        
        # An√°lisis de concordancia entre m√©todos
        concordancia = sum(df_resumen['k_codo'] == df_resumen['k_silueta'])
        total = len(df_resumen)
        print(f"   Concordancia codo-silueta: {concordancia}/{total} ({concordancia/total*100:.1f}%)")
        
        # An√°lisis de calidad general
        print(f"\nüèÜ AN√ÅLISIS DE CALIDAD GENERAL:")
        calidades = df_resumen['calidad_general'].value_counts()
        for calidad, count in calidades.items():
            porcentaje = count / total * 100
            if calidad == 'EXCELENTE':
                emoji = "üåü"
            elif calidad == 'BUENA':
                emoji = "‚úÖ"
            elif calidad == 'REGULAR':
                emoji = "‚ö†Ô∏è"
            else:
                emoji = "‚ùå"
            print(f"   {emoji} {calidad}: {count}/{total} ({porcentaje:.1f}%)")
        
        # Estad√≠sticas de clusters por calidad
        clusters_buenos_total = df_resumen['clusters_buenos'].sum()
        clusters_regulares_total = df_resumen['clusters_regulares'].sum()
        clusters_pobres_total = df_resumen['clusters_pobres'].sum()
        clusters_total = clusters_buenos_total + clusters_regulares_total + clusters_pobres_total
        
        print(f"\nüìä DISTRIBUCI√ìN DE CALIDAD DE CLUSTERS:")
        print(f"   üü¢ Clusters BUENOS: {clusters_buenos_total}/{clusters_total} ({clusters_buenos_total/clusters_total*100:.1f}%)")
        print(f"   üü° Clusters REGULARES: {clusters_regulares_total}/{clusters_total} ({clusters_regulares_total/clusters_total*100:.1f}%)")
        print(f"   üî¥ Clusters POBRES: {clusters_pobres_total}/{clusters_total} ({clusters_pobres_total/clusters_total*100:.1f}%)")
        
        # Mostrar resumen por archivo
        print(f"\nüìä RESUMEN POR ARCHIVO:")
        print("-" * 100)
        print(f"{'Archivo':<30} {'K':<3} {'Silueta':<8} {'Inercia':<8} {'Calidad':<10} {'Filas':<6} {'Clusters'}")
        print("-" * 100)
        
        for _, row in df_resumen.iterrows():
            archivo_corto = row['archivo'][:28] + '..' if len(row['archivo']) > 30 else row['archivo']
            clusters_info = f"[{', '.join([str(row[f'cluster_{i}_size']) for i in range(row['k_final'])])}]"
            
            # Emoji para calidad
            if row['calidad_general'] == 'EXCELENTE':
                emoji_cal = "üåü"
            elif row['calidad_general'] == 'BUENA':
                emoji_cal = "‚úÖ"
            elif row['calidad_general'] == 'REGULAR':
                emoji_cal = "‚ö†Ô∏è"
            else:
                emoji_cal = "‚ùå"
            
            calidad_mostrar = f"{emoji_cal}{row['calidad_general'][:4]}"
            
            print(f"{archivo_corto:<30} {row['k_final']:<3} {row['silueta_final']:<8.4f} {row['inertia_total']:<8.1f} {calidad_mostrar:<10} {row['filas_validas']:<6} {clusters_info}")
        
        print(f"\nüéØ PROCESO COMPLETADO:")
        print(f"   ‚úÖ Todos los gr√°ficos guardados en: k-means/")
        print(f"   ‚úÖ Todos los datasets etiquetados guardados en: {carpeta}/")
        print(f"   ‚úÖ Resumen completo en: k-means/00_resumen_clustering.csv")
        print(f"   üìä Boxplots detallados creados para cada posici√≥n")
    
    else:
        print("‚ùå No se pudo procesar ning√∫n archivo correctamente")

# Ejecutar an√°lisis principal
if __name__ == "__main__":
    # Configurar salida a archivo
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = f'k-means/kmeans_{timestamp}.txt'
    
    # Crear carpeta si no existe
    os.makedirs('k-means', exist_ok=True)
    
    # Configurar redirecci√≥n de salida
    tee = TeeOutput(log_file)
    sys.stdout = tee
    
    try:
        print(f"üìù Salida del an√°lisis guard√°ndose en: {log_file}")
        print(f"üïê Inicio del an√°lisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        
        clustering_todos_archivos()
        
        print("="*60)
        print(f"üïê Fin del an√°lisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üìù Log completo guardado en: {log_file}")
        
    finally:
        # Restaurar salida normal
        sys.stdout = tee.terminal
        tee.close()
        print(f"\n‚úÖ An√°lisis completado. Log guardado en: {log_file}") 